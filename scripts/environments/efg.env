# Copyright [1999-2015] Wellcome Trust Sanger Institute and the EMBL-European Bioinformatics Institute
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#      http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#CONTACT
#
#  Please email comments or questions to the public Ensembl
#  developers list at <http://lists.ensembl.org/mailman/listinfo/dev>.
#
#  Questions may also be sent to the Ensembl help desk at
#  <http://www.ensembl.org/Help/Contact>.



echo "Setting up the Ensembl Function Genomics environment..." 

if [[ $SHELL != */bash ]]; then
    echo "Please initialise bash shell first."
    exit 1;
fi

#Add the auto completes back in as they are lost in subshells
. /etc/profile.d/bash_completion.sh


#Add the following to your .bashrc
#export SRC=~/src
#alias efg='bash --rcfile $SRC/ensembl-funcgen/scripts/environments/efg.env -i'




#Do findbin here

#Nope this only does the pwd from whereit is called
#bin=$( readlink -f -- "$( dirname -- "$0" )" )
#Nope, this return the pwd appended with /bash
#bin=$( readlink -f -- "${0%/*}" ) 
#Nope this is just pwd again!
#bin=$(cd -- "$(dirname "$0")" && pwd) 
#None of the above work when sourcing!!

#echo "bin is bin $bin " 

# To do

# 1 Make template file for efg.config to avoid overwriting custom conf on checkout

# 2 Rename all private methods to start with _ or lcfirst, for EFGHelp filtering
#   _ should never be called from command line, as they are dependant on caller context
#   lcfirst can be, but may not have -h option
#   All ucfirst should have -h option


#Need to export this so other scripts can use it
export funcs_file="$SRC/ensembl-funcgen/scripts/environments/funcs.sh"

if [ -z "$SRC" ]; then
	echo 'You have not defined $SRC in your .bashrc'
	echo 'Adding eFG setup to .bashrc'
	
	echo "Cannot yet findbin when sourcing in bash, add manually"
	exit 1
else
	#Now we need to check for ensembl-funcgen
	#Or can we findbin this?
	#echo 'Need to validate $SRC here'

	if [ ! -e $funcs_file ]; then
		echo "Could not find $funcs_file"
		echo 'Have you set $SRC correctly in your .bashrc?'
		return
	fi
fi


#Source in some handy functions
. $funcs_file


#Now set some constants dependant on funcs

if [[ ! $(isMac) ]]; then
	export HOSTNAME_SWITCH='-f'
fi


#Source in the efg.config
efg_conf_file=$SRC/ensembl-funcgen/scripts/environments/efg.config

if [ ! -e $efg_conf_file ]; then
	echo "Could not find $efg_conf_file"
	echo 'Have you set $SRC correctly in your .bashrc?'
	echo "Maybe you need to set up and edit your efg config: mv efg.config_example efg.config"
	return
fi


. $efg_conf_file


### ENV VARS ###

export ENV_NAME='EFG'



### ALIASES ###
#single quotes enable dynamic updating of commands

alias efg='cd $EFG_SRC'
alias efgd='cd $EFG_DATA'

#We want to add scratch and warehouse aliases here
#For user and group?

alias efgm='cd $EFG_SRC/modules/Bio/EnsEMBL/Funcgen'
alias efgmacs='xemacs $EFG_SRC/modules/Bio/EnsEMBL/Funcgen $EFG_SRC &'

#Change these aliases to funcs so they are exported to scripts run in the environment
#Have to use "$@" to preserve the quoting for -e'some command'!
mysqlw(){ mysql $MYSQL_ARGS -u${DB_USER} "$@";}
mysqlro(){ mysql $MYSQL_ARGS -u${DB_RO_USER} "$@";}
mysqlensdb(){ mysql -hensembldb.ensembl.org -uanonymous -P5306 "$@";} #Assumes you want post 47 DBs
mysqlcore(){ mysql $DNADB_MYSQL_ARGS "$@";}

#can remove this from pipeline.env? As we just redefine $DNADB_MYSQL_ARGS not the alias
alias dasconfdir='cd $EFG_DAS_CONFIG'


_InitEnv(){
  #base colour is blue
  #hive branch (if within repo) in green
  export PS1='\[\033[34m\]${ENV_NAME}:\h\[\033[0;32m\]$(__git_ps1 " (%s)")\[\033[0m\]>'

  echo "Welcome to eFG!"


  #Handle STARTUP_CMD
  #This allows environments to be launched as a remote/interactive job/process
  #i.e. bsub efg to source a pipeline instance file and run a function  e.g. a 6GB DebugJob
  #Will have to do this in the caller, to make sure it's unset in the parent shell

  #If the STARTUP_CMD launches a subshell/remote shell how will this behave on exit?
  #it will exit to efg
  #If this if from an pipeline init file then it will exit to that file
  #so we would have to catch that and return 


  if [[ $STARTUP_CMD ]]; then
     echo -e "Executing STARTUP_CMD:\t$STARTUP_CMD"
     Execute "$STARTUP_CMD"
     export STARTUP_CMD=
  fi     
}

### FUNCTIONS ###

EFGHelp(){

	#Take optional opts here to change regex i.e. include all functions

	OPTIND=1

	usage="EFGHelp\n
Description:\tPrints a list of available aliases and functions\n
Usage:\t\tEFGHelp -h(elp)"

	while getopts ":h" opt; do
		case $opt in 
			h  ) echo -e $usage; return 0;;
            \? ) echo -e $usage; return 1;;
        esac 
    done

	echo ''
	echo 'Available aliases:'
	alias | sed 's/^alias //'
	echo ''
	echo 'Available functions:'
	set | grep -E "^[A-Z][a-zA-Z]+[[:space:]]*\(\)[[:space:]]*$" | sort | sed 's/()//'

	echo -e "\nFor more help try: 'FunctionName' -h"

#Can't match end of line here
	#Change all private methods to start with_ so we don't see them here
	#Prefix everything with env name? so we know where they are and can sort?
	#Or maybe just lcfirst everything we don't want to see?


	#'Analysis'Help should print a brief message, point to the docs and then call this method

}

ListDASSources(){
	#Simply list all sets that are DAS_DISPLAYABLE
	#Do we need this or can we simply look at the ini file?
	
	usage="ListDASSources\n
Description:\tLists available DAS sources and their status\n
Usage:\t\tListDASSets [  -D dbname(default=$DB_NAME) -H dbhost(default=$DB_HOST) -U dbuser(default=$DB_RO_USER) -P dbport(default=$DB_PORT) -W dbpassWord(default=$DB_PASS) -a(ll default is only those which are DAS_DISPLAYABLE) -l(ike MYSQL_LIKE_REGEX) -t(ype result|feature|bed) ]"

	all=
	type=
	db_name=$DB_NAME
	db_port=${DB_PORT:=3306}
	db_user=$DB_RO_USER
	db_host=$DB_HOST
	db_pass=$DB_PASS
	db_pass_arg=
	db_port_arg=
	like=
	valid_types='feature result bed'
	OPTIND=1

	while getopts ":at:D:H:U:P:W:l:h" opt; do
		case $opt in 
            a  ) all=1 ;;
            t  ) type=$OPTARG ;;
			D  ) db_name=$OPTARG ;;
            H  ) db_host=$OPTARG ;;
			#Change this to take a list of hosts?
			U  ) db_user=$OPTARG ;;
            P  ) db_port=$OPTARG ;;
			W  ) db_pass=$OPTARG ;;
			l  ) like=$OPTARG ;;
			h  ) echo -e $usage; return 0;;
            \? ) echo -e $usage; return 1;;
        esac 
    done

	valid_types='result feature bed'
	
	if [ $type ]; then
		error=$(ValidateVariableOrUsage "$usage" type valid_types)
	
		if [ $? -ne 0 ]; then
			echo $error
			return 1;
		fi
	fi

	types=${type:=$valid_types}
	error=$(CheckVariablesOrUsage "$usage" db_name db_user db_port db_host)

	if [ $? -ne 0 ]; then
		echo $error
		return 1;
	fi

	#Define mysql optional args
	if [ $db_pass ]; then
		db_pass_arg="-p$db_pass"
	fi

	if [ $db_port ]; then
		db_port_arg="-P$db_port "
	fi


	sql=
	like_clause=
	like_title=

	if [ $like ]; then

		if [ $all ]; then 
			like_clause=" where t.name like \"$like\" "
		else
			like_clause=" and t.name like \"$like\" "		
		fi

		like_title="like '$like'"

	fi
	
	for type in $types; do

		   #if [[ $type =~ "result|feature" ]]; then #This does not work in mac bash!        

		   if [[ $type = "result" ]] || [[ $type = "feature" ]]; then


			#We could do a union to get them in the same table


			table="${type}_set"
			title=$(echo $table | tr [a-z] [A-Z])
		
			echo "$title DAS Sources $like_title"

			#Do we want display_label for feature_sets?
			sql="SELECT t.name as \"Set Name\", \"$type\" as \"Set Type\", sn.name as \"DAS State\", ${table}_id from $table t"
	
			if [ $all ]; then
	
				#Make table alias including only DAS_DISPLAYABLE records to avoid product on left join
				sql="$sql left join (select s.table_id, s.table_name, sn1.name from status s, status_name sn1 where  s.status_name_id=sn1.status_name_id and sn1.name='DAS_DISPLAYABLE') sn  on sn.table_id=t.${table}_id and sn.table_name='$table' $like_clause";
			
			else
				sql="$sql, status s, status_name sn where s.table_id=t.${table}_id and s.table_name=\"$table\" and s.status_name_id=sn.status_name_id and sn.name=\"DAS_DISPLAYABLE\" $like_clause"
			fi

			#echo "mysql -e \"$sql\" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name"

			#Don't Execute as we don't want to exit
			mysql -e "$sql" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name

		else
			#Deal with bed tables
			#Need to status tables to bed DB schema if not funcgen
			#Then we can set status
			#This should be added to LoadBedDASSources
			sql="show tables like 'bed\_%${like}'"
			echo "BED DAS Sources $like_title"
			
			#echo "mysql -e \"$sql\" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name"
	
			mysql -e "$sql" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name	
		
		
			#Need to add like here
			
			#Formatting not consistent
			#tables=$(mysql -e "$sql" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name)

			#echo "BED DAS Sources"
			#cnt=0

			#for table in $tables; do
				
			#	cnt=$(($cnt+1))

			#	if [[ $cnt -gt 2 ]]; then
			#		echo $table
			#	fi
			#done
		fi
	done
	
}

#This is currently not reseting the SourceAdaptor timeout!

TurnOnDASSource(){
	usage="TurnOnDASSource\n
Description:\tSets DAS_DISPLAYABLE status for result or feature sets\n
Usage:\t\tTurnOnDASSource -t(ype result|feature|bed) (-n(ame) | -l(ike_string e.g. '%my_exp_name%') [ -i(d only required for non-unique result_set names) -D dbname(default=$DB_NAME) -H dbhost(default=$DB_HOST) -U dbuser(default=$DB_USER) -P dbport(default=$DB_PORT) -W dbpassWord(default=$DB_PASS) ]"


	type=
	off=
	name=
	like_string=
	ids=
	db_name=$DB_NAME
	db_port=${DB_PORT:=3306}
	db_user=$DB_USER
	db_host=$DB_HOST
	db_pass=$DB_PASS
	db_pass_arg=
	db_port_arg=
	valid_types='feature result bed'
	OPTIND=1

	while getopts ":t:n:l:i:oD:H:U:P:W:h" opt; do
		case $opt in 
            t  ) type=$OPTARG ;;
            n  ) name=$OPTARG ;;
			l  ) like_string=$OPTARG ;;	
            i  ) ids=$OPTARG ;;
			o  ) off=1 ;;
			D  ) db_name=$OPTARG ;;
			H  ) db_host=$OPTARG ;;
			#Change this to take a list of hosts?
			U  ) db_user=$OPTARG ;;
            P  ) db_port=$OPTARG ;;
			W  ) db_pass=$OPTARG ;;
			h  ) echo -e $usage; return 0;;
            \? ) echo -e $usage; return 1;;
        esac 
    done

	valid_types='feature bed result'
	#No result yet as we haven't implemented status tables in bed only schema
	#

	error=$(ValidateVariableOrUsage "$usage" type valid_types)
	
	if [ $? -ne 0 ]; then
		echo -e $error
		return 1;
	fi


	error=$(CheckVariablesOrUsage "$usage" type db_name db_user db_port db_host)

	if [[ ! "$name" ]] && [[ ! "$like_string" ]] && [[ ! "$id" ]]; then
		echo -e $usage
		return 1
	fi

	if [ $? -ne 0 ]; then
		echo -e $error
		return 1;
	fi

	#Define mysql optional args
	if [ $db_pass ]; then
		db_pass_arg="-p$db_pass"
	fi

	if [ $db_port ]; then
		db_port_arg="-P$db_port "
	fi


	#Grab the DAS_DISPLAYABLE status_name_id first just incase it isn't present?
	#This is in the efg.sql schema, so it should always be there
	
	table="${type}_set"
   
	#We need to handly non-unique result_set names here!

	if [ ! $ids ]; then

		#Can't have name and like_string

		if [[ "$name" ]] && [[ "$like_string" ]]; then
			echo -e "Mutually exclusive options:\t-n and -l"
			echo -e $usage
		fi
		
		if [[ "$name" ]]; then
		#Get set_id first to validate
			sql="select ${table}_id from $table where name='$name'"
			ids=($(echo $(mysql -e "$sql" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name) | sed "s/${table}_id //"))
	        #Should be using QueryVal(needs to sort out clash between pipeline and efg QueryVal) for this?
	        #Now test we have only one ids
			no_ids=${#ids[@]}
		
			if [ $no_ids -gt 2 ]; then
				echo -e "There is more than on $table with the name:\t$name "
				echo -e "Please specify a table_id:\t"${ids[*]}
				return 1
			fi
		else # Must have $like_string
			sql="select ${table}_id from $table where name like '$like_string'"
			ids=($(echo $(mysql -e "$sql" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name) | sed "s/${table}_id //"))
			no_ids=${#ids[@]}
		fi

		if [ $no_ids -eq 0 ]; then
			tmp=${name:=$like_string}
			echo -e "Could not find the $table:\t$tmp"
			return 1
		fi

	
		#id=${ids[1]}

	else
		ids=($ids)

		#validate id against name
		#Should use QUeryVal here
		sql="select name from $table where ${table}_id='${ids[0]}'"
		tmp=($(mysql -e "$sql" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name))


		if [[ ${tmp[1]} != $name ]]; then
			echo "The id(${ids[0]}) and $table name($name) does not match the name in the DB(${tmp[1]})"
		fi
	fi


	for id in ${ids[*]}; do

		if [ $off ]; then
			sql="DELETE s from status s, status_name sn where s.table_id=$id and s.table_name='$table' and s.status_name_id=sn.status_name_id and sn.name='DAS_DISPLAYABLE'"
		else
			sql="INSERT IGNORE into status SELECT '$id', '$table', status_name_id from status_name where name='DAS_DISPLAYABLE'"
		fi
		
		mysql -e "$sql" -h$db_host -u$db_user $db_pass_arg $db_port_arg $db_name		
	done

	if [ $db_pass ]; then
		db_pass_arg="-W $db_pass"
	fi

	if [ $db_port ]; then
		db_port_arg="-P $db_port "
	fi


	#Reset timeout?
	


	#Now show what we have turned it on or off
	ListDASSources -t $type -D $db_name -H $db_host -U $db_user $db_pass_arg $db_port_arg -a -l $name
}


TurnOffDASSource(){
	echo "Using TurnOnDASSource with -o(ff) option"
	TurnOnDASSource $* -o
}


LoadBedDASSources(){
	time perl $EFG_SRC/scripts/DAS/load_bed_source.pl $*
	return
	

	#This should also GenerateDASConfig for the given host?
	#Or keep this separate?
	#Need to extend generate_DAS_config.pl to support Das DB
	#i.e. need to parse table_name to generate attrs
	#Or just swwith to hydra for other
	#Hydra will need to have several sources
	#One for each set type per DB
	# i.e. one for the bed DB
	# one for the feature sets in the eFG DB
	# one for the result sets in the eFG DB
	# If the Das BED tables are integrated into the eFG DB
	# How will the adaptor know which tables to use?


	#Need to add -farm flag here? Or always submit to farm?
	#Maybe -no_farm

		#Reset/Declare ind and vars/defaults
	OPTIND=1
	instance=
	das_port=$EFG_DAS_PORT
	das_host=$EFG_DAS_HOST
	das_config=$EFG_DAS_CONFIG
	xsl_home=
	#Default to current working DB details
	species=$SPECIES
	db_name=$DB_NAME
	db_port=${DB_PORT:=3306}
	db_user=$DB_USER
	db_host=$DB_HOST
	db_pass=$DB_PASS
	db_pass_arg=
	db_port_arg=

	files=
	names=
	reads=
	profile=
	bin_size=
	frag_length=
	prefix=
	#Others?
	#no_load
	#profile_input
	
	

	#Getting lots of opts here!
	#Keep DASconfig separate?

	#test $0 here?
	usage='LoadBedDASSources: Loads a DAS source from a BED file as raw alignments or an alignment profile.\n
usage: LoadBedDASSources -i das_instance_name [ -c das_config(default=$EFG_DAS_CONFIG) -p das_port(default=$EFG_DAS_PORT) -s das_host(default=$EFG_DAS_HOST) -D dbname(default=$DB_NAME) -H dbhost(default=$DB_HOST) -U dbuser(default=$DB_USER) -P dbport(default=$DB_PORT) -W dbpassWord(default=$DB_PASS) -S latin_species_name -f feature_set -r result_set -h(elp) -x styleshome ]'

	#We really need to implement getOptArgArray?
	#for -f(iles) -n(ames)

	#Need to add options for individual set config?
	#These could be set as env defaults?
	#We already have some script defaults
	#Not yet implemented in script

	while getopts ":i:p:s:c:D:H:U:P:W:S:f:n:rhab:l:X:NI" opt; do
		case $opt in 
	        i  ) instance=$OPTARG ;; 
            c  ) das_config=$OPTARG ;;
            u  ) das_user=$OPTARG ;;
            p  ) das_port=$OPTARG ;;
            s  ) das_host=$OPTARG ;;
            x  ) xsl_home=$OPTARG ;;
			D  ) db_name=$OPTARG ;;
            H  ) db_host=$OPTARG ;;
			U  ) db_user=$OPTARG ;;
            P  ) db_port=$OPTARG ;;
			W  ) db_pass=$OPTARG ;;
			S  ) species=$OPTARG ;;
            f  ) _setOptArgArray files $* ;; #files=($OptArgArray) ;;
            n  ) _setOptArgArray names $* ;; #names=($OptArgArray) ;;
            r  ) reads=' --reads ' ;;
            a  ) profile=' --profile ' ;;
			b  ) bin_size=" --bin_size $OPTARG ";;
			l  ) frag_length="--frag_length $OPTARG" ;;
			X  ) prefix="--prefix =$OPTARG" ;;
			N  ) no_load='--no_load' ;;
			I  ) profile_input='--profile_input' ;;
            h  ) echo -e $usage; return 0;;
            \? ) echo -e $usage; exit 1;;
        esac 
    done



	#Shall we also check other vars here so that the env doesn't exit?

	error=$(CheckVariablesOrUsage "$usage" instance das_port das_host das_config db_name db_user db_port db_host EFG_DAS_HOME files)

	#Let script handle this?
	#if ( ! ([ $reads ] || [  $profile ])); then
	#	echo 'You must supl

		#Is this catching correctly?
	if [ $? -ne 0 ]; then
		echo $error
		return 1;
	fi



	#Define for script
	if [ $db_pass ]; then
		db_pass_arg="--dbpass $db_pass"
	fi

	if [ $db_port ]; then
		db_port_arg="--db_port $db_port "
	fi

	#Now run load script
	perl $EFG_SRC/scripts/DAS/load_bed_source.pl \
		--host $db_host\
		--user $db_user\
		--dbname $db_name\
		$db_port_arg\
		$db_pass_arg\
		--files ${files[*]}\
		--names ${names[*]}\
		$prefix\
		$reads\
		$profile\
		$no_profile\
		$bin_size\
		$frag_length\
		$profile_input



	#Just return if the load failed
	if [ $? -ne 0 ]; then
		return 1
	fi



	#now redefine for GenerateDASConfig opt
	if [ $db_pass ]; then
		db_pass_arg="-W $db_pass"
	fi

	if [ $db_port ]; then
		db_port_arg="-P $db_port "
	fi

	if [ ! $xsl_home ]; then
		xsl_home=" -x ${EFG_DAS_HOME}/stylesheets "	
	else
		xsl_home=" -x $xsl_home "
	fi	

	#Or should we do this separately?
	#We don't need to do this after loading a hydra source!!
	#GenerateDasConfig 


}

GenerateDASConfig(){

	
	#Need to add dasdb stuff here for the Bed sources?
	#Or do we need a flag for using bed/profile DB?
	#Just switch to hydra
	#Is result_feature display working yet?
	
	#Need to add options to set hydra config
	#for each type e.g. all bed tables, displayable feature/resultsets

	#Do we now need to separate out code to set dispayable states?
	#As we may not need to regenerate conf unless we have added a source type
	#MakeSetDASDisplayable
	#This would require ListDASSets -result_sets -feature_sets -bed_sets

	#Separate tables prevents data in normal table from being displayed using same code
	#Can we not just use the same table?
	#Here we hit partitioning problem?
	#We never load just reads into DB normally
	#Just implement as is for now

	#echo "This method has been deprecated. Please use $EFG_SRC/scripts/DAS/generate_DAS_config.pl (-h for help)"

	perl $EFG_SRC/scripts/DAS/generate_DAS_config.pl $*

	return

	#Reset/Declare ind and vars/defaults
	OPTIND=1
	instance=
	das_port=$EFG_DAS_PORT
	das_host=$EFG_DAS_HOST
	das_config=$EFG_DAS_CONFIG
	feature_set=
	result_set=
	xsl_home=
	#Default to current working DB details
	species=$SPECIES
	db_name=$DB_NAME
	db_port=${DB_PORT:=3306}
	db_user=$DB_USER
	db_host=$DB_HOST
	db_pass=$DB_PASS

	#Hydra stuff
	not_hydra=
	#default all types, adaptor will pick out displayable
	source_types='feature_set result_set bed'
	

	
	usage='usage: GenerateDASConfig -i das_instance_name [ -c das_config(default=$EFG_DAS_CONFIG) -p das_port(default=$EFG_DAS_PORT) -s das_host(default=$EFG_DAS_HOST) -D dbname(default=$DB_NAME) -H dbhost(default=$DB_HOST) -U dbuser(default=$DB_USER) -P dbport(default=$DB_PORT) -W dbpassWord(default=$DB_PASS) -S latin_species_name -f feature_set -r result_set -x styleshome -n(not_hydra)-t sourceTypes(default=(feature_set result_set bed) -h(elp) ]'


	#Need to add options for individual set config?
	#These could be set as env defaults?
	#We already have some script defaults
	#Not yet implemented in script


	#Need to add severroot, maintainer

	while getopts ":i:p:s:c:D:H:U:P:W:S:f:r:h" opt; do
		case $opt in 
	        i  ) instance=$OPTARG ;; 
            c  ) das_config=$OPTARG ;;
            u  ) das_user=$OPTARG ;;
            p  ) das_port=$OPTARG ;;
            s  ) das_host=$OPTARG ;;
            x  ) xsl_home=$OPTARG ;;
			D  ) db_name=$OPTARG ;;
            H  ) db_host=$OPTARG ;;
			U  ) db_user=$OPTARG ;;
            P  ) db_port=$OPTARG ;;
			W  ) db_pass=' --dbpass $OPTARG ';;
			S  ) species=$OPTARG ;;
			f  ) feature_set=$OPTARG ;;
            r  ) result_set=$OPTARG ;;	
			n  ) not_hydra=' --not_hydra ' ;;
			t  ) _setOptArgArray source_types $* ;;  #Should this be $@ to avoid spliting 'words with' with spaces?
            h  ) echo $usage; return 0;;
            \? ) echo $usage; exit 1;;
        esac 
    done

	#There is no way we can set the display names for each individual set
	#Should we allow group config?
	#This would require modifying display_names directly in the ini file?
	#f  ) feature_sets='$OPTARG $feature_sets' ;;
    #        r  ) result_sets='$OPTARG $result_sets' ;;

    #Can we use $MYSQL_SCRIPT_ARGS here?

	error=$(CheckVariables instance das_port das_host das_config db_name db_user db_port db_host EFG_DAS_HOME)

	
	if [ $? -ne 0 ]; then
		echo -e "$usage"
		echo -e "$error"
		return 1;
	fi



	if [ ! $xsl_home ]; then
		xsl_home=" -styleshome ${EFG_DAS_HOME}/stylesheets "
	else
		error=$(CheckFiles xsl_home)
	
	 	if [ $? -ne 0 ]; then
			echo -e "-x styleshome parameter cannot be found\n$error"
			echo -e "$usage"
			return 1
		fi

		xsl_home=" -styleshome $xsl_home "
	fi


	#We should just let the script handle all the parameter checking here!
	#Need to check params as we don't want a misleading hepl message from the script?
	#Can we just drop this func and use the script with env var defaults?


	if [ $result_set ] && [ $feature_set ]; then
		echo 'Cannot specifiy both -r(esult_set) and -f(eature_set). Can only add/custom configure one set at a set'
		return 1;
	fi

	set_string=

	if [ $result_set ]; then
		set_string=" -set_type result -set_name $result_set "
	elif [ $feature_set ]; then
		set_string=" -set_type feature -set_name $result_set "
	fi

	if [ $source_types ]; then
		source_types=" --source_types ${source_types[*]}"
	fi
	
	perl $EFG_SRC/scripts/DAS/generate_DAS_config.pl \
		-species $species\
		-dbport $db_port\
		-dbhost $db_host\
		-dbuser $db_user\
		-dbname $db_name\
		$db_pass\
		$xsl_home \
		$not_hydra\
		$source_types\
		-das_host $das_host\
		-das_port $das_port\
		-das_config $das_config\
		-das_name $instance

}


StartDASServer(){
	#This needs to cat config/html files for a given DAS instance
	#And restart/start the server as necessary
	
	#Reset/Declare ind and vars/defaults
	OPTIND=1
	instance=
	das_port=$EFG_DAS_PORT
	das_host=$EFG_DAS_HOST
	das_config=$EFG_DAS_CONFIG
	no_fork=
	debug=
	usage='usage: StartDASServer -i das_instance_name [ -c das_config(default=$EFG_DAS_CONFIG) -p das_port(default=$EFG_DAS_PORT) -s das_host(default=$EFG_DAS_HOST) -x(no fork) -h(elp) -d(ebug) ]'

	while getopts ":i:c:p:s:xdh" opt; do
		case $opt in 
	        i  ) instance=$OPTARG ;; 
            c  ) das_config=$OPTARG ;;
            p  ) das_port=$OPTARG ;;
            s  ) das_host=$OPTARG ;;
            x  ) no_fork=' -x ' ;;
            d  ) debug=' -debug ' ;;
h  ) echo $usage; return 0;;
\? ) echo $usage; exit 1;;
        esac 
    done

#		d  ) das_home=$OPTARG ;;


	error=$(CheckVariables instance das_port das_host das_config EFG_DAS_HOME)

	if [ $? -ne 0 ]; then
		echo -e "$error"
		echo -e "$usage"
		return 1;
	fi


	#Validate EFG_DAS_HOME here i.e. check it is a ProServer?


    #CheckHost 	
	#-f is not valid for Darwin
	#


	fq_domain_name=$(hostname $HOSTNAME_SWITCH)

	#This is because we don't want to accidentally start a DAS server on the wrong host
	#if we have logged into/been sent to a different host
	#This may cause problem if this is running from a laptop
	#i.e. the hostname is dynamically assigned by the network
	#and not easily comparable to localhost?

	if [ "$das_host" != "$fq_domain_name" ]; then

		echo -e "WARNING:\tYou have specified the das_host '$das_host' but appear to be running from '$fq_domain_name'"
		#echo -e "WARNING:\tYou must run this from the DAS host($das_host). You are currently logged into $fq_domain_name"
		#echo "WARNING:\tOver-riding $das_host with $fq_domain_name"
		echo -e "WARNING:\tMaybe you want to reset change the das_host or run this from a different host?"
		#das_host=$fq_domain_name
	#return 1

	fi

	#Do we need to validate this against the header file?
	#We could have individual directories for each db
	#and individual files for each source?
	#This way we could easily add and remove individual sources
	
	#Currently we can't restart the server using this func as the input files are deleted

	#Cannot use : in instance name here as Bio::Das::Proserver::Config truncates!
	instance_name=${instance}.${das_host}.${das_port}	
	config_header=${das_config}/${instance_name}.config.header
	html_header=${das_config}/${instance_name}.html.header
	error='Maybe you need to GenerateDASConfig?'
	
	#Subshell this so we just return instead of exiting the env
	error=$(CheckFilesOrUsage "$error" config_header html_header)
	
	if [ $? -ne 0 ]; then
		echo $error;
		return 1;
	fi


	#Now list files using patterns based on instance name

	#+ does not work here? how did it ever?

	#Pipe this through grep to make sure we only get file matchign regex rather than imprecise glob

	config_files=$(ls ${das_config}/${instance}.*.sources | grep -E "${das_config}/${instance}\..+\.[0-9]+\..*\.[a-zA-Z]+\.sources")
	html_files=$(ls ${das_config}/${instance}.*.html | grep -E "${das_config}/${instance}\..+\.[0-9]+\..*\.[a-zA-Z]+\.html")

	
	for list in "$html_files" "$config_files"; do
 
		if [[ $list = "*No such file*" ]]; then
			echo $list
			return 1
		fi
	done


	#Stop the server
	#Before we start messing aroung with the config
	StopDASServer -i $instance -c $das_config -p $das_port -s $das_host


	#Now check there isn't another process listening on the port
	running_process=$(netstat -an | grep -E ':$das_port[[:space:]]+[0-9]+' | grep -i listen)
	#could add -p here to get pid/name but need to be root
	
	if [ "$running_process" ]; then
		echo "There is already a process listening on port $das_port"
		echo $running_process
		return 1;
	fi


	#Cat the config files
	config_file=${das_config}/${instance_name}.ini
	BackUpFile $config_file
	cat $config_header $config_files > $config_file
	
	#Cat the html files
	html_file=${das_config}/${instance_name}.html
	BackUpFile $html_file
	cat $html_header $html_files > $html_file
	#Now add the footer
	echo '</body></html>' | cat >> $html_file

	#Start the server
	echo "Starting DAS server with:"
	echo "$EFG_DAS_HOME/eg/proserver $no_fork $debug -c $config_file"

	perl $EFG_DAS_HOME/eg/proserver $no_fork $debug -c $config_file
	
	if [ $? -ne 0 ]; then
		echo "Failed to start DAS instance: $instance_name"
		return 1
	elif [ ! $no_fork ]; then
		echo "Started DAS instance: $instance_name"
		echo "You can check out your DAS server home page here: http://${das_host}:${das_port}"
	fi

}


StopDASServer(){
	echo ":: StopDASServer $*"
	#This makes sure we reset the getopts ind if we have used it previously
	OPTIND=1

	instance=
	das_config=$EFG_DAS_CONFIG
	das_port=$EFG_DAS_PORT
	das_host=$EFG_DAS_HOST
	usage='usage: StopDASServer -i das_instance_name [ -c das_config(default=$EFG_DAS_CONFIG) -p das_port(default=$EFG_DAS_PORT) -s das_host(default=$EFG_DAS_HOST) -h(elp) ]'


	#Can we take array_names here too
	#Is this wise to restrict to arrays within a linked set


	while getopts ":i:p:s:c:h" opt; do
		case $opt in 
	        i  ) instance=$OPTARG ;; 
            p  ) das_port=$OPTARG ;;
            s  ) das_host=$OPTARG ;;
			c  ) das_config=$OPTARG ;; 
h  ) echo $usage; return 0;;
\? ) echo $usage; exit 1;;
        esac 
    done


	error=$(CheckVariables instance das_port das_host das_config)

	if [ $? -ne 0 ]; then
		echo -e "$error"
		echo -e "$usage"
		return 1;
	fi

	
    #CheckHost 	
	fq_domain_name=$(hostname $HOSTNAME_SWITCH)

	if [ "$das_host" != "$fq_domain_name" ]; then
		echo -e "WARNING:\tYou have specified the das_host '$das_host' but appear to be running from '$fq_domain_name'"
		#echo -e "WARNING:\tYou must run this from the DAS host($das_host). You are currently logged into $fq_domain_name"
		#echo "WARNING:\tOver-riding $das_host with $fq_domain_name"
		echo "WARNING:\tMaybe you want to reset change the das_host or run this from a different host?"
		#das_host=$fq_domain_name
	fi


	instance_name=${instance}.${das_host}.${das_port}

	#Stop the server
	pid_file=${das_config}/${instance_name}.pid

	if [ -f $pid_file ]; then
		pid=$(cat $pid_file)
		ps $pid

		if [ $? -eq 0 ]; then
			kill -TERM $pid

			if [ $? -ne 0 ]; then
				echo "Failed to stop DAS instance($pid): $instance_name"
				return 1
			else
				echo "Stopped DAS instance: $instance_name"
			fi

		else
			echo "$instance_name DAS instance($pid) is not running"
		fi
	else
		echo "Could not find proserver pid file: $pid_file"
	fi
}


ForwardDASPorts(){
    #echo ":: ForwardDASPorts $*"

	#Here we need to remote forward the DAS port via an ssh tunnel
	#to a publicly visible host and port
	#Hence we can then choose the local(ssh terms) machine(i.e. the machine we've tunneled to) as the
	#das host with the forwarded port

	#This makes sure we reset the getopts ind if we have used it previously
	OPTIND=1

	#instance=
	#Could validate this versus the config file and warn?
	das_port=$EFG_DAS_PORT
	das_host=$EFG_DAS_HOST
	ssh_host=
	public_host=
	public_port=
	public_user=
	ssh_user=$USER
	local_ssh_port=9022
	remote_ssh_port=10022
	public_ssh_alias=
	config=
	no_execute=
	usage='Description:\tSet up remote ssh port forwarding from non-public(e.g.desk/laptop) to publicly visible machine.
\n\t\tRequires ssh remote login to be enabled on das_host(MACOSX:\tSystemPreferences>Sharing)\nqUsage:\t\tForwardDASPorts -H public_host -S ssh_host [ -U ssh_User(default is $USER) -p das_port(default=$EFG_DAS_PORT) -P public_port(default=das_port) -s das_host(default=$EFG_DAS_HOST) -c(onfig, print ssh config/command) -l(ocal_shh_port for localfoward to public_host default=9022) -r(emote_ssh_port for remote forward to das_host default=10022) -a public_ssh_alias(ssh alias for public_host which has local and remote ssh(22) forwards configured in $HOME/.shh/config)  -h(elp) ]'

	while getopts ":H:P:U:S:p:s:a:l:r:ch" opt; do
		case $opt in 
	            H  ) public_host=$OPTARG ;; 
		    P  ) public_port=$OPTARG ;; 
		    U  ) ssh_user=$OPTARG ;;
		    S  ) ssh_host=$OPTARG ;;
		    p  ) das_port=$OPTARG ;;
		    s  ) das_host=$OPTARG ;;
		    a  ) public_ssh_alias=$OPTARG ;;
		    l  ) local_ssh_port=$OPTARG ;;
		    r  ) remote_ssh_port=$OPTARG ;;
		    c  ) config=1 ;;
		    h  ) echo -e $usage; return 0;;
		    \? ) echo -e $usage; return 1;;
		esac 
	done


	#Don't need local_ssh_port if we have alias
	#Don't need to check ssh_ports if we have defaults above

	error=(CheckVariables public_host public_port public_user das_port das_host)


	if [ $? -ne 0 ]; then
		echo -e "$error"
		echo -e "$usage"
		return 1;
	fi

	REPLY=                                                                                                                                 
        while [ "$REPLY" != 'yes' ]; do
	    AskQuestion "Have you enabled remote login on your das_host($das_host)? Type 'yes' to continue"
	done     

	public_port=${public_port:=$das_port}
	#Default to direct ssh connection to public_host if no ssh gateway host provided
	ssh_host=${ssh_host:=$public_host}
	#This should still work?
	

	#telnet_txt="Once logged into the $public_host. You can test the port has been forwarded via telnet:
#telnet localhost $public_port
#Now simply enter some text to elicit a error response from the DAS server.
#Alternatively go to http://localhost:$public_port
#WARNING:\tThis is no guarantee that this will be publicly available, just that the port has beem remotely forward properly
#If this is not available via the Ensembl browser using ${public_host}:${public_port} then it could be that your sysadmin does not allow these ports to be visible to the public"
	


	if [ $config ]; then
	    echo "Not yet implemented"
#		echo -e "Before you set up any of these SSH tunnels you may want to log into 
#$public_host to check there are no processes listening on port $public_port
#Do this with:\tnetstat -an | grep -E ':$public_port[[:space:]]+[0-9]+' | grep -i listen"

			#you can test this has been forward to the public_host machine
	#by logging in and telneting to the localhost on the public incoming port



	else

	    #We have already checked the das_port on the localhost/das_host when we started the DAS server
			    
	    #Build like this to prevent $ interpolation
	    #cmd='running_process=$'
	    #cmd=$cmd"(netstat -an | grep -E \"[\.:]$public_port[[:space:]]+[\*0-9]+\" | sed \"s/\*\.\*/\\\*\\\.\\\*/\");"
            # | grep -i listen);"# removed this listen as we are missing other ports
	    #any *.* caught here will glob all the file names when echoed!
	    #Let's sed this to prevent confusion
	    #cmd=$cmd'if [ "$running_process" ]; then '
	    #cmd=$cmd'echo $running_process; else echo "PORT FREE"; fi'
            #cmd=$cmd" echo $telnet_txt"  
		
	    #No guarantee the the shell used by ssh to execute the command will be the                                                                                                                   
            #same as the normal login shell, so this needs t be shell agnostic!
            #sourcing bash doesn't work!


	    ssh_cmd="ssh -L $local_ssh_port:$public_host:22 -l $ssh_user $ssh_host"

	    REPLY=
	    while [ "$REPLY" != 'yes' ]; do
		
		    #Need to build this meesage dependant on alias
		
		AskQuestion "\nIf you have configured your local($local_ssh_port) and remote($remote_ssh_port) forwards to $public_host in $HOME/.ssh/config please check your ports match and log into your ssh gateway($ssh_host) in a separate shell(maybe you want to specify a public_ssh_alias?). Otherwise execute the following in a separate shell:\n\t$ssh_cmd\nType 'yes' to continue"
		    #or can we just put this in the background?
	    done

	    
 	    #Test port fowarded to correct host 
	    public_alias=${public_ssh_alias:="$ssh_user@localhost -p$local_ssh_port"}
	    test_host=$(ssh $public_alias -f 'hostname -f')
	    port_alias=                                                                                                                                                                                  
            
            if [ $alias ]; then                                                                                                                                                                          
                port_alias="public_alias($public_ssh_alias)"                                                                                                                                                 
            else                                                                                                                                                                                         
                port_alias="local_ssh_port($local_ssh_port)"                                                                                                                                             
            fi 

	    echo -e "\nTesting ssh connection to $public_host on localhost via $port_alias"
	    
	    if [ "$test_host" != "$public_host" ]; then
		
		echo -e "FAILURE:\tConnection to public_host $public_host through $public_alias failed"
		echo -e "\t\tHost check via ssh on localhost:$local_ssh_port gives:\t$test_host"
		return 1
	    else
		echo -e "OK"
	    fi
	    
		#Test public_port is available on public_host
		#Tests all active ports on the local machine, listening/established (also works on mac)
	    netstat_cmd="netstat -an | grep -E \"[\.:]$public_port[[:space:]]+[\*0-9]+\" | sed \"s/\*\.\*/\\\*\\\.\\\*/\"" 		
	    ssh_cmd="ssh $public_alias -f '$netstat_cmd'"

		#$ssh_cmd
		#$? is always 0 if ssh command executed cleanly
		#Does not return the exit status of the command!!
		#Need to catch output 
		#$? here will be subshell $? not ssh $? ??? 
	    in_use_ports=$(eval $ssh_cmd)
	    
	    echo -e "\nTesting public_port $public_port is free on public_host $public_host"
	    
	    if [ "$in_use_ports" ]; then
		echo -e $in_use_ports
		echo -e "FAILURE:\tPort $public_port appears to be in use on $public_host\nPlease choose another(-P)" 
		return 1
	    else
		echo -e "OK"
	    fi
	    
	    
		#We could have public_host alias here if config is already set?
		#Need to set up localforward via alias if one has been specified as the remote forward in the config will only be activated by the alias?
		#Would need to remore -R from here if we have remote forward already set up in alias config
	    
		#We are putting this into the back ground
		#on the public_host here so it is obvious that this is the tunnel
		#Can we do the same for the first command, and then we can keep working on the localhost?
		#Or do we want to make it obvious that this is the tunnel terminal?
		#ssh_cmd="ssh -R $remote_ssh_port:localhost:22  $public_ssh_alias -p $local_ssh_port 'ssh -N -L $das_port:localhost:$public_port ${USER}@localhost -p $remote_ssh_port -g &'"
		
		#This should log back into the localhost(desk/laptop) but seems to do that in the back ground leaving you on public_server
		#Problems with this chained command not working, this seems to hang, with not connection established
		#Hitting CTRL-D once exits *something* and then it works??
	        #Work around...

		
		ssh_cmd="echo 'ssh -T -N -L $das_port:localhost:$public_port ${USER}@localhost -p $remote_ssh_port -g &' | ssh -R  $remote_ssh_port:localhost:22  $public_alias"    
                
		#This does leave hung terminal on the ssh_host :(
		#We could potentially fork the first(after pipe) command, but this would leave us on the public host.

		echo -e "\nNOTE:\tThe following process will ssh back and forth to and from the public_host($public_host) to up the DAS port forwards"
		echo -e "\tThe final ssh connection is intended to hang so it can no longer be used as an interactive terminal."
		echo -e "\tThis is done to highlight this process/terminal as the DAS tunnel, hence helping to prevent inadvertant"
		echo -e "\tterminal closure or any further inefficient traffic across this double tunneled connection."

		echo -e "\nNOTE:\tThe previous or following ssh commands may show some 'Warning' output dependant on what ports you have already forwarded"
		echo -e "\tYou can largely ignore these unless the process exits"

		echo -e "\nNOTE:\tTo test the das_port has been forwarded:\t ssh $public_alias 'telnet localhost $public_port'"
		echo -e "\tThis should give you a html error response if you enter text and hit return."
		echo -e "\tTo test the das server is visible visit:\thttp://$public_host:$public_port/" 

		echo -e "\nSetting up DAS port forwards:\t$ssh_cmd"

		eval $ssh_cmd
		
		echo -e "\nNOTE:\tIf 'Privileged ports' error is shown, this refers to public_port $public_port(-p)"

		#error=$(eval $ssh_cmd)
		#echo -e "error is $error"
		#if [[ $error =~ "Privileged" ]]; then
		#    echo -e "Maybe you want to pick a higher number port(~9000)?"
		#fi

		#Sub shell does not catch all of error, therefore can't reliably test
		

		#Initial implementation given remote forwarding to the public host is allowed
	        #ssh -t -X -R 9000:localhost:9000 ssh.sanger.ac.uk ssh -o GatewayPorts=yes -R 9000:localhost:9000 bc-9-1-01.internal.sanger.ac.uk
		#No as problem is because the problem is the remote forward, not the gatewayports as this is fine for a local forward


		#The alternate to this is to do the 2nd forward as a localforward from the public machine
		#to the previously remotely forwarded port. This does however require ssh remote login to 
		#be enabled on the localmachine(desk/laptop)
		
		#Need to add -g option for gateway, otherwise we can ssh directly into the machine
		#This should work for standard ebi set uo
		#probably need an opt for sanger gateway style set up
		#may also need separate user name for second foward
		
		#Non gateway option would be simple remote forward direct to public host

		# Protocol
		# 1 ssh from das_host to gateway setting up localforward(PORT1) to public server
		# 2 Set up remote forward(PORT2) by sshing das_host to public server via localforward from 1
		# 3 Set up final localfoward(DAS_PORT) from public server to das_host via remoteforward in 2
		#We extra ports for:
		# 1 The ssh tunnel to the public machine (which will host the 
		# 2 The ssh tunnel

		# Is the separate shell going to cause problems?
		# Can't we just print the command or config to run in separate window and then procede with next bit after AskQuestion
		#Each of these ports needs to be tested!
		

	fi


}


CreateDB(){

	#This makes sure we reset the getopts ind if we have used it previously
	OPTIND=1

	drop=
	skip=
	species=
	pass=
	dbname=
	dnadb_host=
	usage='usage: CreateDB -d dbname -p password -s(pecies) e.g. e.g homo_sapiens [ -f(orce drop database) -t(skip type import) -H (dnadb host)]'


	#Can we take array_names here too?
	#Is this wise to restrict to arrays within a linked set?


	#Do we need to add dnadb params here?
	#And maybe override args for other db params
	#or should we provide a UseHost function?

	while getopts ":d:p:hfs:tH:" opt; do
		case $opt in 
		    d  ) dbname=$OPTARG ;; 
                    p  ) pass=$OPTARG ;;
		    f  ) drop=1 ;;
			t  ) skip=1 ;;
			s  ) species=$OPTARG ;;
			H  ) dnadb_host=$OPTARG;;
			h  ) echo $usage; return 0;;
			\? ) echo $usage; exit 1;;
	esac 
	done

	error=$(CheckVariables dbname pass)

 	if [ $? -ne 0 ]; then
		echo -e $error
		echo "$usage"
		return 1;
	fi


	#We should do some validation of the dbname here


    present=$(_QueryVal show databases like \"$dbname\")
     
    if [[ $present ]]
    then

        if [[ $drop ]]
        then
            echo ":: Dropping DB $dbname"
			#Need to Execute this
			mysqlw -p${pass} -e "DROP DATABASE IF EXISTS $dbname"
        else
            echo "DB $dbname already exists, please drop the database manually specify -f(orce) to drop the DB'"
            return
        fi
    fi

    echo ":: Creating DB $dbname"
    echo "CREATE database $dbname" | mysqlw -p${pass}
    mysqlw -p${pass} $dbname < $EFG_SQL/efg.sql


	#Now insert schema_version into meta to avoid warnings
	#Should really validate dbname first
	#Need separate method for this
	
	#schema_version=($(GetSchemaBuild $dbname))
	#This error does not get caught as it is brackets
	schema_version=$(GetSchemaBuild $dbname)
	
	if [ $? -ne 0 ]; then
		echo -e $schema_version
		return 1
	fi
	
	#space separated string as an array
	schema_version=($schema_version)
	schema_version=${schema_version[0]}

	echo ":: Setting meta schema_version to $schema_version"
	#mysqlw -p${pass} -e "INSERT into meta(meta_key, species_id, meta_value) values('schema_version', NULL, '$schema_version')" $dbname
	mysqlw -p${pass} -e "UPDATE meta set meta_value='$schema_version' where meta_key='schema_version'" $dbname


	#Now import the standard Cell/FeatureTypes
	if [ ! $skip ]; then

		error=$(CheckVariables species)

		if [ $? -ne 0 ]; then
			echo $error
			echo "You need to specify a species(-s) if you want to pre-load Cell/FeatureTypes(or skip with -t)"
		else
			echo ":: Pre-loading Cell/FeatureTypes"


			if [ $dnadb_host ]; then
				dnadb_host=" -dnadb_host $dnadb_host "
			fi

			#These only ever need to be pointed at staging or ensembldb
			#So no need for all dnadb params just host and port for forwarded ports
			#We are actually using DNADB_SCRIPT_ARGS instead which is non-obvious?
			#Need to allow override here?

			perl $EFG_SRC/scripts/import/import_type.pl -dnadb_host $DNADB_HOST -dnadb_port $DNADB_PORT -dnadb_user $DNADB_USER -host $DB_HOST -user $DB_USER -port $DB_PORT -dbname $dbname -species $species -pass $pass -type Analysis -file $EFG_SRC/scripts/import/types/Analyses.txt $dnadb_host
		
			perl $EFG_SRC/scripts/import/import_type.pl -dnadb_host $DNADB_HOST -dnadb_port $DNADB_PORT -dnadb_user $DNADB_USER -host $DB_HOST -user $DB_USER -port $DB_PORT -dbname $dbname -species $species -pass $pass -type FeatureType -file $EFG_SRC/scripts/import/types/FeatureTypes.txt $dnadb_host

			perl $EFG_SRC/scripts/import/import_feature_type_associations.pl -dnadb_host $DNADB_HOST -dnadb_port $DNADB_PORT -dnadb_user $DNADB_USER -host $DB_HOST -user $DB_USER -port $DB_PORT -dbname $dbname -species $species -pass $pass -file $EFG_SRC/scripts/import/types/FeatureType_associations.txt

			gene_links_file=$EFG_SRC/scripts/import/types/${species}.FeatureType_Genes.txt
		#Not present for all species
			
			if [ -e $gene_links_file ]; then
			    perl $EFG_SRC/scripts/import/import_feature_type_gene_links.pl -dnadb_host $DNADB_HOST -dnadb_port $DNADB_PORT -dnadb_user $DNADB_USER -host $DB_HOST -user $DB_USER -port $DB_PORT -dbname $dbname -species $species -pass $pass -file $gene_links_file
			else
			    echo "WARNING: Could not find Gene Links file: $gene_links_file"
			    echo "Either generate this file and re-run CreateDB or use import_feature_type_gene_links.pl"
			fi

			cell_types_file=$EFG_SRC/scripts/import/types/${species}.CellTypes.txt
		#Not present for all species

			if [ -e $cell_types_file ]; then

				perl $EFG_SRC/scripts/import/import_type.pl -dnadb_host $DNADB_HOST -dnadb_port $DNADB_PORT -dnadb_user $DNADB_USER -host $DB_HOST -user $DB_USER -port $DB_PORT -dbname $dbname -species $species -pass $pass -t CellType -file $EFG_SRC/scripts/import/types/${species}.CellTypes.txt $dnadb_host
			else
				echo "WARNING: Could not find CellType file: $cell_types_file"
				echo "Either generate this file and re-run CreateDB or use import_type.pl"
			fi

			echo "Setting meta species.ensembl_latin_name=$species"
			mysqlw -p${pass} -e "INSERT into meta(meta_key, species_id, meta_value) values('species.production_name', 1, '$species')" $dbname

			echo "Addind efg as default experimental group"
			mysqlw -p${pass} -e "INSERT INTO experimental_group (name,location,contact,description,url,is_project) VALUES ('efg','EMBL-EBI','http://lists.ensembl.org/mailman/listinfo/dev','default experimental group','http://www.ensembl.org',0)" $dbname;

		fi


	fi

	echo ":: Created $dbname"	
}


#This should always be called via subshell to return an array
#e.g. $schema_build =($(GetSchemaBuild rattus_norvegicus_funcgen_57a_34y))
#Hence always have to catch $?, and can use return instead of exit for nicer cmdline usage?

GetSchemaBuild(){
	dbname=$1

	if [ ! $dbname ]; then
		echo 'To GetSchemaBuild you must provide a dbname argument'
		return 1
	fi

	dbname_array=$(echo $dbname | sed 's/_/ /g')
	#Turn space separated string into array
	dbname_array=($dbname_array)
	schema_posn=${#dbname_array[*]}
		
	schema_posn=$(( $schema_posn - 2 ))	
	schema_version=${dbname_array[$schema_posn]}
	build=${dbname_array[(($schema_posn +1))]}
	
	#Does this =~ work in mac bash?

	if [[ ! $schema_version =~ ^[[:digit:]]+$ ]] || [[ ! $build =~ ^[[:digit:]]+[a-z]*$ ]]; then
		echo "WARNING: Could not identify a valid schema_version($schema_version) or build($build) from your dbname: $dbname"
		echo "Please rename your db as follows: any_prefix_latin_species_funcgen_SCHEMA_BUILD[n] e.g. my_homo_sapiens_funcgen_54_36p"
		return 1;
	fi


	echo $schema_version $build
}


CreateLocalDB(){
	TMP=$MYSQL_ARGS
	MYSQL_ARGS=" -P${DB_PORT}";
	CreateDB $@
	export MYSQL_ARGS=$TMP


}


#This clashes with pipeline.env QueryVal
#and breaks CreateDB due to mysqlro and MYSQLARGS

_QueryVal(){

    #need to check if PASS defined else use READ_NAME
    val=$(echo $* | mysqlro)

	#should capture error here
	#this works differently if passing a var or passing a quoted string, var get's split
	#do not quote query!
	echo $val | sed "s/$2 //"
}




UseBranch(){
	branch=$1

	if [[ ! $branch ]]
    then
		echo "Need to define and API version to create softlinks for"
		echo "UseBranch 50"
	return
    fi 


	#Should really test for softlinks here to avoid deleting a directory

	modules=('ensembl ensembl-funcgen')

	cdir=$PWD

	cd $SRC

	for module in $modules
	do
		if [ -e $module ]
		then

  			if [ -L $module ]
			then
				rm -f $module		
			else
				echo "Failed: Module $module is not a symbolic link, please rectify by moving to vBRANCH dir"
				return
			fi
		fi
	
		if [ -d v$branch/$module ]
	  	then
	   		ln -s v$branch/$module $module
	   	else
	   		#could do cvs check out here
	   		echo "You have not yet checked out v$branch/$module"
	   		return
	   	fi
	done

	echo "Now using v$branch for modules: $modules"

	cd $cdir

}


GetRegulatoryAttributeSets(){
	
	#echo ":: GetRegulatoryAttributeSets $*"
	#This makes sure we reset the getopts ind if we have used it previously
	OPTIND=1

	user=$DB_USER
	dbname=$DB_NAME
	host=$DB_HOST
	port=$DB_PORT
	pass=$PASS
	field=name
	name_clause=
	version=
	usage='usage: GetRegulatoryAttributeSets -u(ser $DB_USER) -h(ost $DB_HOST) -d(bname $DB_NAME) [ -p(assword $PASS) -P(ort $DB_PORT) -f(ield name) -s(set_name by default returns all) -v(ersion e.g 4 default is current) -h(elp) ]'


	while getopts ":u:d:H:p:P:v:f:s:h" opt; do
		case $opt in 
	        u  ) user=$OPTARG ;; 
            d  ) dbname=$OPTARG ;;
            H  ) host=$OPTARG ;;
			P  ) port=$OPTARG ;; 
			p  ) pass=$OPTARG ;;
			f  ) field=$OPTARG ;;
			s  ) name_clause=$OPTARG ;;
			v  ) version=$OPTARG ;;
			h  ) echo $usage; return 0;;
			\? ) echo $usage; exit 1;;#Do we want exit here?
        esac 
    done

		
	CheckVariables user dbname host

	#Set some more defaults
	port=${port:=3306}
	
	if [ $pass ]; then 
		pass="-p${PASS}"
	fi

	if [ $version ]; then
		version="_v${version}"
	fi

	#WHat is this?
	if [[ $field != '*' ]]; then
		field="$field as '' "
	fi
	
	if [ "$name_clause" ]; then 
		name_clause=" ds.name='${name_clause}' ";
	else
		name_clause=" ds.name like 'RegulatoryFeature%' ";
	fi

	#group_concat is truncated by default to 1024
	#This is also not working with multiple sets!

	sql="select ds.name, group_concat(fs.${field}) from data_set ds, supporting_set ss, feature_set fs where $name_clause and ds.data_set_id=ss.data_set_id and ss.supporting_set_id=.fs.feature_set_id order by fs.name";


	echo $sql
	#Can we QueryVal this?

	#we need to strip the header if field is not *
	
	

	mysql -e "$sql" -h$host -u$user $pass -P$port $dbname | sed '/^$/d'


}
export HISTCONTROL=ignoreboth
export HISTSIZE=1000000000
shopt -s histappend
PROMPT_COMMAND='history -a'
PROMPT_COMMAND="${PROMPT_COMMAND:+$PROMPT_COMMAND ; }"'echo $$ $USER "$(history 1)" >> ~/.bash_eternal_history'
export BEH="${HOME}/.bash_eternal_history"
_InitEnv




#Should we add QC methods here or keep these in the sql/perl script?
#Maybe we can source these in as different function module?
#Or is this better kept in perl but separate from API methods?
