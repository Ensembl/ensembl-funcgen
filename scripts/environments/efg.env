#!/usr/local/bin/bash

echo "Setting up the Ensembl Function Genomics environment..." 
#add alias efg='. ~/path/to/your/ensembl-functgenomics/scripts/environments/efg.env' to your .bashrc


#Need to take options SRC arg here or check whether is exists
#If it doesn't then append it to .bashrc along with alias

#Do findbin here

#Nope this only does the pwd from whereit is called
#bin=$( readlink -f -- "$( dirname -- "$0" )" )
#Nope, this return the pwd appended with /bash
#bin=$( readlink -f -- "${0%/*}" ) 
#Nope this is just pwd again!
#bin=$(cd -- "$(dirname "$0")" && pwd) 
#None of the above work when sourcing!!

#echo "bin is bin $bin " 

funcsfile="$SRC/ensembl-functgenomics/scripts/environments/funcs.sh"

if [ -z "$SRC" ]; then
	echo 'You have not defined $SRC in your .bashrc'
	echo 'Adding eFG setup to .bashrc'
	
	echo "Cannot yet findbin when sourcing in bash, add manually"
	exit 1
else
	#Now we need to check for ensembl-functgenomics
	#Or can we findbin this?
	#echo 'Need to validate $SRC here'

	if [ ! -e $funcsfile ]; then
		echo "Could not find $funcsfile"
		echo 'Have you set $SRC correctly in your .bashrc?'
		return
	fi
fi


#Source in some handy functions
. $funcsfile

### ENV VARS ###

export ENV_NAME='EFG'

#Prompt
export PS1="efg@\h> "

# Group data
export EFG_GROUP='eFG'                          #EDIT
export EFG_LOCATION='Hinxton, Cambridge'        #EDIT
export EFG_CONTACT='your@email.ac.uk'           #EDIT

#Code/Data Directories
#export SRC=$HOME/src                            #Root source code directory. EDIT This should be set in your .bashrc
export EFG_SRC=$SRC/ensembl-functgenomics       #eFG source directory
export EFG_SQL=$EFG_SRC/sql                     #eFG SQL
export EFG_DATA=$HOME/data/efg   #Data directory. EDIT

export EFG_PERL=/software/bin/perl
export PATH=$PATH:$EFG_SRC/scripts              #eFG scripts directory
export PERL5LIB=$EFG_SRC/modules:$PERL5LIB      #Update PERL5LIB. EDIT add ensembl(core) etc. if required

#Your efg DB connection params
#These may change to DB_HOST inline with pipeline.env
export EFG_WRITE_USER="ensadmin"                    #EDIT
export EFG_READ_USER="ensro"                        #EDIT
export EFG_HOST='ens-genomics1'                     #EDIT
export EFG_PORT=3306                                #EDIT
export MYSQL_ARGS="-h${EFG_HOST} -P${EFG_PORT}"         
#pass always supplied on cmd line e.g. mysqlw -p your password

#Your ensembl core DB connection params, read only
export DNADB_USER='ensro'                        #EDIT if required e.g. anonymous
export DNADB_HOST='ens-staging'                  #EDIT if required e.g. ensembldb.ensembl.org
export DNADB_PORT=3306                           #EDIT if required
export DNADB_SCRIPT_ARGS="-dnadb_host $DNADB_HOST -dnadb_user $DNADB_USER -dnadb_port $DNADB_PORT"
#could do with a quick method to change these between ens-livemirror, ensembldb/ensdb-archive?

#DAS params
export EFG_DAS_CONFIG=$EFG_SRC/config/DAS       #DAS config dir where pid and config files are written
export EFG_DAS_HOST=$(hostname -f)              #DAS sever host, set to $(hostname -f) or EDIT?
export EFG_DAS_PORT=9876                        #Default DAS port EDIT
export EFG_DAS_NAME=efg                         #DAS instance name EDIT
export EFG_DAS_HOME=$SRC/Bio-Das-ProServer      #DAS code dir, must be ProServer!
#This is currently added to the PERL5LIB in .cshrc
#But we need to be mindful of this growing for unrelated processes
#i.e. this will slow initialisation of other jobs(lsf!)


#Default norm and analysis methods

export NORM_METHOD='VSN_GLOG'                   #EDIT if required e.g. T.Biweight, Loess
export PEAK_METHOD='Nessie'                     #EDIT if required e.g. TileMap, MPeak, Chipotle


#could do with a quick method to change these between ens-livemirror, ensembldb/ensdb-archive?
#R config
export R_LIBS=${R_LIBS:=$SRC/R-modules}
export R_PATH=/software/bin/R-2.7.1-dev
export R_FARM_PATH=/software/bin/R-2.7.1
export R_BSUB_OPTIONS="-R'select[type==X86_64 && mem>6000] rusage[mem=6000]' -q bigmem"


#need to check/define R_LIBS here
#could add PERL5LIB here too, this could be extended to include all config for shipping to users?  in bashrc for now
#should check for input and output dirs here and create with a question
#would need to sed file to set permanently?

#Source in some handy functions
. $EFG_SRC/scripts/environments/funcs.sh

### ALIASES ###
#single quotes enable dynamic updating of commands

alias efg='cd $EFG_SRC'
alias efgd='cd $EFG_DATA'
alias efgm='cd $EFG_SRC/modules/Bio/EnsEMBL/Funcgen'
alias efgmacs='xemacs $EFG_SRC/modules/Bio/EnsEMBL/Funcgen &'
alias mysqlw='mysql $MYSQL_ARGS -u${EFG_WRITE_USER}'
alias mysqlro='mysql $MYSQL_ARGS -u${EFG_READ_USER}'
alias das_config='cd $EFG_DAS_CONFIG'

#check for vars then suggest defaults or take stdin?

echo "Welcome to eFG!"


### FUNCTIONS ###


#ListDASSets(){
	#Simply list all sets that are DAS_DISPLAYABLE
	#Do we need this or can we simply look at the ini file?
#}


#We also need funcs here to remove config for given sets?
#ListNonDASSets?

GenerateDASConfig(){

	#Reset/Declare ind and vars/defaults
	OPTIND=1
	instance=
	das_port=$EFG_DAS_PORT
	das_host=$EFG_DAS_HOST
	das_config=$EFG_DAS_CONFIG
	feature_set=
	result_set=
	xsl_home=
	#Default to current working DB details
	species=$SPECIES
	db_name=$DB_NAME
	db_port=${DB_PORT:=3306}
	db_user=$DB_USER
	db_host=$DB_HOST
	db_pass=$DB_PASS
	
	usage='usage: GenerateDASConfig -i das_instance_name [ -c das_config(default=$EFG_DAS_CONFIG) -p das_port(default=$EFG_DAS_PORT) -s das_host(default=$EFG_DAS_HOST) -D dbname(default=$DB_NAME) -H dbhost(default=$DB_HOST) -U dbuser(default=$DB_USER) -P dbport(default=$DB_PORT) -W dbpassWord(default=$DB_PASS) -S latin_species_name -f feature_set -r result_set -h(elp) -x styleshome ]'


	#Need to add options for individual set config?
	#These could be set as env defaults?
	#We already have some script defaults
	#Not yet implemented in script

	while getopts ":i:p:s:c:D:H:U:P:W:S:f:r:h" opt; do
		case $opt in 
	        i  ) instance=$OPTARG ;; 
            c  ) das_config=$OPTARG ;;
            u  ) das_user=$OPTARG ;;
            p  ) das_port=$OPTARG ;;
            s  ) das_host=$OPTARG ;;
            x  ) xsl_home=$OPTARG ;;
			D  ) db_name=$OPTARG ;;
            H  ) db_host=$OPTARG ;;
			U  ) db_user=$OPTARG ;;
            P  ) db_port=$OPTARG ;;
			W  ) db_pass=$OPTARG ;;
			S  ) species=$OPTARG ;;
			f  ) feature_set=$OPTARG ;;
            r  ) result_set=$OPTARG ;;		
            h  ) echo $usage; return 0;;
            \? ) echo $usage; exit 1;;
        esac 
    done

	#There is no way we can set the display names for each individual set
	#Should we allow group config?
	#This would require modifying display_names directly in the ini file?
	#f  ) feature_sets='$OPTARG $feature_sets' ;;
    #        r  ) result_sets='$OPTARG $result_sets' ;;

    #Can we use $MYSQL_SCRIPT_ARGS here?

	error=$(CheckVariablesOrUsage "$usage" instance das_port das_host das_config db_name db_user db_port db_host EFG_DAS_HOME)

	if [ ! $xsl_home ]; then
		xsl_home=" -styleshome ${EFG_DAS_HOME}/stylesheets "
	else
		error='-x styleshome parameter cannot be found' 
		error=$(CheckFilesOrUsage "$error" xsl_home)
	
	 	if [ $? -ne 0 ]; then
 			echo $error;
			return 1
		fi

		xsl_home=" -styleshome $xsl_home "
	fi

	#Is this catching correctly?

	if [ $? -ne 0 ]; then
		echo $error
		return 1;
	fi


	if [ $result_set ] && [ $feature_set ]; then
		echo 'Cannot specifiy both -r(seult_set) and -f(eature_set). Can only add/custom configure one set at a set'
		return 1;
	fi

	set_string=

	if [ $result_set ]; then
		set_string=" -set_type result -set_name $result_set "
	elif [ $feature_set ]; then
		set_string=" -set_type feature -set_name $result_set "
	fi

	
	if [ $db_pass ]; then
		db_pass="-dbpass $db_pass"
	fi

	
	$EFG_SRC/scripts/DAS/generate_DAS_config.pl \
	-species $species\
	-dbport $db_port\
	-dbhost $db_host\
	-dbuser $db_user\
	-dbname $db_name\
	$db_pass $xsl_home \
	-das_host $das_host\
	-das_port $das_port\
	-das_config $das_config\
	-das_name $instance

}


StartDASServer(){
	#This needs to cat config/html files for a given DAS instance
	#And restart/start the server as necessary

	#Reset/Declare ind and vars/defaults
	OPTIND=1
	instance=
	das_port=$EFG_DAS_PORT
	das_host=$EFG_DAS_HOST
	das_config=$EFG_DAS_CONFIG
	no_fork=
	usage='usage: StartDASServer -i das_instance_name [ -c das_config(default=$EFG_DAS_CONFIG) -p das_port(default=$EFG_DAS_PORT) -s das_host(default=$EFG_DAS_HOST) -x(no fork) -h(elp) ]'

	while getopts ":i:d:p:s:c:xh" opt; do
		case $opt in 
	        i  ) instance=$OPTARG ;; 
            c  ) das_config=$OPTARG ;;
            p  ) das_port=$OPTARG ;;
            s  ) das_host=$OPTARG ;;
            x  ) no_fork=' -x ' ;;
h  ) echo $usage; return 0;;
\? ) echo $usage; exit 1;;
        esac 
    done

#		d  ) das_home=$OPTARG ;;


	#This isn't working if we don't set -i???
	$(CheckVariablesOrUsage "$usage" instance das_port das_host das_config EFG_DAS_HOME)

	echo "$instance $das_port $das_host $das_config"


	if [ $? -ne 0 ]; then
		echo $error
		return 1;
	fi


	#Validate EFG_DAS_HOME here i.e. check it is a ProServer?


    #CheckHost 	
	fq_domain_name=$(hostname -f)

	if [ $das_host != $fq_domain_name ]; then
		echo "You must run this from the DAS host($das_host). You are currently logged into $fq_domain_name"
		return 1
	fi

	#Do we need to validate this against the header file?
	#We could have individual directories for each db
	#and individual files for each source?
	#This way we could easily add and remove individual sources
	
	#Currently we can't restart the server using this func as the input files are deleted

	#Cannot use : in instance name here as Bio::Das::Proserver::Config truncates!
	instance_name=${instance}.${das_host}.${das_port}	
	config_header=${das_config}/${instance_name}.config.header
	html_header=${das_config}/${instance_name}.html.header
	error='Maybe you need to GenerateDASConfig?'
	
	#Subshell this so we just return instead of exiting the env
	error=$(CheckFilesOrUsage "$error" config_header html_header)
	
	if [ $? -ne 0 ]; then
		echo $error;
		return 1;
	fi


	#Now list files using patterns based on instance name
	config_files=$(ls ${das_config}/${instance}.*.*.*.*Set.sources)
	html_files=$(ls ${das_config}/${instance}.*.*.*.*Set.html)
	
	for list in "$html_files" "$config_files"; do
 
		if [[ $list = "*No such file*" ]]; then
			echo $list
			return 1
		fi
	done


	#Stop the server
	#Before we start messing aroung with the config
	StopDASServer -i $instance -c $das_config -p $das_port -s $das_host

	#Cat the config files
	config_file=${das_config}/${instance_name}.ini
	BackUpFile $config_file
	cat $config_header $config_files > $config_file
	#rm -f $config_header $config_files
	
	#Cat the html files
	html_file=${das_config}/${instance_name}.html
	BackUpFile $html_file
	cat $html_header $html_files > $html_file
	#rm -f $html_header $html_files
	#Now add the footer
	echo '</body></html>' | cat >> $html_file

	#Start the server
	$EFG_DAS_HOME/eg/proserver $no_fork -debug -c $config_file
	
	if [ $? -ne 0 ]; then
		echo "Failed to start DAS instance: $instance_name"
		return 1
	elif [ ! $no_fork ]; then
		echo "Started DAS instance: $instance_name"
	fi

}


StopDASServer(){
	echo ":: StopDASServer $*"
	#This makes sure we reset the getopts ind if we have used it previously
	OPTIND=1

	instance=
	das_config=
	das_port=
	das_host=
	usage='usage: StopDASServer -i das_instance_name [ -c das_config(default=$EFG_DAS_CONFIG) -p das_port(default=$EFG_DAS_PORT) -s das_host(default=$EFG_DAS_HOST) -h(elp) ]'


	#Can we take array_names here too
	#Is this wise to restrict to arrays within a linked set


	while getopts ":i:p:s:c:h" opt; do
		case $opt in 
	        i  ) instance=$OPTARG ;; 
            p  ) das_port=$OPTARG ;;
            s  ) das_host=$OPTARG ;;
			c  ) das_config=$OPTARG ;; 
h  ) echo $usage; return 0;;
\? ) echo $usage; exit 1;;
        esac 
    done


	das_port=${das_port:=$EFG_DAS_PORT}
	das_host=${das_host:=$EFG_DAS_HOST}
	das_config=${das_config:=$EFG_DAS_CONFIG}


	error=$(CheckVariablesOrUsage "$usage" instance das_port das_host das_config)

	if [ $? -ne 0 ]; then
		echo $error;
		return 1;
	fi

	
    #CheckHost 	
	fq_domain_name=$(hostname -f)

	if [ $das_host != $fq_domain_name ]; then
		echo "You must run this from the DAS host($das_host). You are currently logged into $fq_domain_name"
		return 1
	fi


	instance_name=${instance}.${das_host}.${das_port}

	#Stop the server
	pid_file=${das_config}/${instance_name}.pid

	if [ -f $pid_file ]; then
		pid=$(cat $pid_file)
		ps $pid

		if [ $? -eq 0 ]; then
			kill -TERM $pid

			if [ $? -ne 0 ]; then
				echo "Failed to stop DAS instance($pid): $instance_name"
				return 1
			else
				echo "Stopped DAS instance: $instance_name"
			fi

		else
			echo "$instance_name DAS instance($pid) is not running"
		fi
	else
		echo "No such instance configured: $pid_file"
	fi
}




CreateDB(){

	#This makes sure we reset the getopts ind if we have used it previously
	OPTIND=1

	drop=
	skip=
	species=
	pass=
	dbname=
	usage='usage: CreateDB -d dbname -p password -s(pecies) e.g. e.g homo_sapiens [ -f(orce drop database) -t(skip type import)]'


	#Can we take array_names here too?
	#Is this wise to restrict to arrays within a linked set?


	#Do we need to add dnadb params here?
	#And maybe override args for other db params
	#or should we provide a UseHost function?

	while getopts ":d:p:hfs:t" opt; do
		case $opt in 
	        d  ) dbname=$OPTARG ;; 
	p  ) pass=$OPTARG ;;
	f  ) drop=1 ;;
	t  ) skip=1 ;;
    s  ) species=$OPTARG ;;
	h  ) echo $usage; return 0;;
	\? ) echo $usage; exit 1;;
	esac 
	done

	error=$(CheckVariablesOrUsage "$usage" dbname pass)

	if [ $? -ne 0 ]; then
		echo $error;
		return 1;
	fi



	#We should do some validation of the dbname here


    present=$(QueryVal show databases like \"$dbname\")
     
    if [[ $present ]]
    then

        if [[ $drop ]]
        then
            echo "Dropping DB $dbname"
			#Need to Execute this
			mysqlw -p${pass} -e "DROP DATABASE IF EXISTS $dbname"
        else
            echo "DB $dbname already exists, please drop the database manually specify -f(orce) to drop the DB'"
            return
        fi
    fi

    echo "Creating DB $dbname"
    echo "CREATE database $dbname" | mysqlw -p${pass}
    mysqlw -p${pass} $dbname < $EFG_SQL/efg.sql


	#Now insert schema_version into meta to avoid warnings
	#Should really validate dbname first
	
	schema_version=$(echo $dbname | sed 's/_/ /g')
	#Turn space separated string into array
	schema_version=($schema_version)
	schema_posn=${#schema_version[*]}
		
	schema_posn=$(( $schema_posn - 2 ))	
	schema_version=${schema_version[$schema_posn]}
	
	if [[ ! $schema_version =~ ^[[:digit:]]+$ ]]; then
		echo "WARNING: Could not identify a valid schema_version($schema_version) from your dbname: $dbname"
		echo "Please rename your db as follows: any_prefix_latin_species_funcgen_SCHEMA_BUILDn e.g. my_homo_sapiens_funcgen_54_36p"
		return 1;
	fi

	mysqlw -p${pass} -e "INSERT into meta(meta_key,meta_value) values('schema_version', '$schema_version')" $dbname
	#We are still getting warnings after this


	#Now import the standard Cell/FeatureTypes
	if [ ! $skip ]; then

		error=$(CheckVariablesOrUsage "$usage" species)

		if [ $? -ne 0 ]; then
			echo $error;
			return 1;
		fi

		$EFG_SRC/scripts/import/import_type.pl $DNADB_SCRIPT_ARGS -host $EFG_HOST -dbname $dbname -species $species -pass $pass -type FeatureType -file $EFG_SRC/scripts/import/types/FeatureTypes.txt

		cell_types_file=$EFG_SRC/scripts/import/types/${species}.CellTypes.txt

		if [ -e $cell_types_file ]; then

			$EFG_SRC/scripts/import/import_type.pl $DNADB_SCRIPT_ARGS -host $EFG_HOST -dbname $dbname -species $species -pass $pass -t CellType -file $EFG_SRC/scripts/import/types/${species}.CellTypes.txt
		else
			echo "WARNING: Could not file CellType file: $cell_types_file"
			echo "Either generate this file and re-run CreateDB or use import_type.pl"
		fi


	fi
	
	
}

CreateLocalDB(){
	TMP=$MYSQL_ARGS
	MYSQL_ARGS=" -P${EFG_PORT}";
	CreateDB $@
	export MYSQL_ARGS=$TMP


}


#This clashes with pipeline.env QueryVal
#and breaks CreateDB due to mysqlro and MYSQLARGS

QueryVal(){

    #need to check if PASS defined else use READ_NAME
    val=$(echo $* | mysqlro)

	#should capture error here
	#this works differently if passing a var or passing a quoted string, var get's split
	#do not quote query!
	echo $val | sed "s/$2 //"
}



RunUsage(){
	#do run usage first then run the parse_and_import.pl script

	echo "Usage: run.sh 'password' [result files]"
	echo "       ARG[0]: 'password' - the write password to the import db specified in run.sh"
	echo "       ARG[@]: optional - list of result files to use during import, currently only works for Sanger import"

}

#This can be moved to funcs.sh ?

UseBranch(){
	branch=$1

	if [[ ! $branch ]]
    then
		echo "Need to define and API version to create softlinks for"
		echo "UseBranch 50"
	return
    fi 


	#Should really test for softlinks here to avoid deleting a directory

	modules=('ensembl ensembl-functgenomics')

	cdir=$PWD

	cd $SRC

	for module in $modules
	do
		if [ -e $module ]
		then

  			if [ -L $module ]
			then
				rm -f $module		
			else
				echo "Failed: Module $module is not a symbolic link, please rectify by moving to vBRANCH dir"
				return
			fi
		fi
	
		if [ -d v$branch/$module ]
	  	then
	   		ln -s v$branch/$module $module
	   	else
	   		#could do cvs check out here
	   		echo "You have not yet checked out v$branch/$module"
	   		return
	   	fi
	done

	echo "Now using v$branch for modules: $modules"

	cd $cdir

}

#Change this to EFGHelp
#Then have PipelineHelp
#ArrayHelp
#FuncsHelp
#Call all other helps with -a
#etc
#These will largely just be a little note describing the environment and then a list of the functions
#This can be done dynamically by greping the env file
#HelpUsage(){
#	RunUsage
#
#	parse_and_import.pl -help
#}
#Can we use set here to print out the code?

#Maybe move this to pipeline.env and use mysqlefg?
#No leave here and just default to DB params if not set

GetRegulatoryAttributeSets(){
	
	#echo ":: GetRegulatoryAttributeSets $*"
	#This makes sure we reset the getopts ind if we have used it previously
	OPTIND=1

	user=$DB_USER
	dbname=$DB_NAME
	host=$DB_HOST
	port=$DB_PORT
	pass=$PASS
	field=name
	version=
	usage='usage: GetRegulatoryAttributeSets -u(ser $DB_USER) -h(ost $DB_HOST) -d(bname $DB_NAME) [ -p(assword $PASS) -P(ort $DB_PORT) -f(ield name) -v(ersion e.g 4 default is current) -h(elp) ]'


	while getopts ":u:d:H:p:P:v:f:h" opt; do
		case $opt in 
	        u  ) user=$OPTARG ;; 
            d  ) dbname=$OPTARG ;;
            H  ) host=$OPTARG ;;
			P  ) port=$OPTARG ;; 
			p  ) pass=$OPTARG ;;
			f  ) field=$OPTARG ;;
			v  ) version=$OPTARG ;;
			h  ) echo $usage; return 0;;
			\? ) echo $usage; exit 1;;#Do we want exit here?
        esac 
    done

		
	CheckVariables user dbname host

	#Set some more defaults
	port=${port:=3306}
	
	if [ $pass ]; then 
		pass="-p${PASS}"
	fi

	if [ $version ]; then
		version="_v${version}"
	fi

	if [[ $field != '*' ]]; then
		field="$field as '' "
	fi
	
	sql="select fs.${field} from data_set ds, supporting_set ss, feature_set fs where ds.name='RegulatoryFeatures${version}' and ds.data_set_id=ss.data_set_id and ss.supporting_set_id=.fs.feature_set_id order by fs.name";

	#Can we QueryVal this?

	#we need to strip the header if field is not *
	
	

	mysql -e "$sql" -h$host -u$user $pass -P$port $dbname | sed '/^$/d'


}



#Should we add QC methods here or keep these in the sql/perl script?
#Maybe we can source these in as different function module?
#Or is this better kept in perl but separate from API methods?
